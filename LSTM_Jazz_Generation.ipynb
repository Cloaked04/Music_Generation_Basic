{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f11e44a2908>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.chord.Chord C4 A3 E4 G3 F2> 4.0\n",
      "<music21.note.Note F> 4.0\n",
      "<music21.note.Note E> 4.0\n",
      "<music21.note.Note G#> 4.0\n",
      "<music21.note.Note B> 4.0\n",
      "<music21.note.Note G#> 4.25\n",
      "<music21.note.Note G#> 4.5\n",
      "<music21.note.Note G#> 4.75\n",
      "<music21.note.Note G#> 5.0\n",
      "<music21.note.Note E> 5.0\n"
     ]
    }
   ],
   "source": [
    "file = \"midi/original_metheny.mid\"\n",
    "midi = converter.parse(file)\n",
    "parsedNotes = midi.flat.notes\n",
    "\n",
    "#Printing only first 10 note objects\n",
    "for element in parsedNotes[:10]:\n",
    "    print(element, element.offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parsing file 0   midi/original_metheny.mid*********************\n",
      "If instrument part\n",
      "s2: <music21.stream.Score 0x7f11908c91d0>\n",
      "After adding instrument part: <music21.stream.iterator.RecursiveIterator for Part:Piano @:0>\n",
      "**********************\n",
      "Notes:\n",
      " ['4.5.7.9.0', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', '4.5.7.9.0', 'G#2', 'G#2', 'G#2', '9.10.2.5', 'C3', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2']\n",
      "Lenght notes:\n",
      " 3265\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "for i,file in enumerate(glob.glob(\"midi/*.mid\")):\n",
    "    midi = converter.parse(file)\n",
    "    print('\\r', 'Parsing file', i, \" \", file, end='')\n",
    "    parsedNotes = None\n",
    "    #print(parsedNotes)\n",
    "    try: #check if file has instrument part\n",
    "        print(\"*********************\")\n",
    "        print(\"If instrument part\")\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        print(\"s2:\",s2)\n",
    "        parsedNotes = s2.parts[0].recurse()\n",
    "        print(\"After adding instrument part:\",parsedNotes)\n",
    "        print(\"**********************\")\n",
    "    except: #file has notes in flat structure\n",
    "        print(\"Printing if notes part:\",midi.flat.notes)\n",
    "        parsedNotes = midi.flat.notes\n",
    "        print(\"Printing after adding notes: \",parsedNotes)\n",
    "        print(\"**********************\")\n",
    "        \n",
    "    for element in parsedNotes:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "print(\"Notes:\\n\",notes[:20])\n",
    "print(\"Lenght notes:\\n\",len(notes))\n",
    "\n",
    "with open('notes', 'wb') as filepath:\n",
    "    pickle.dump(notes, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocab: 143\n",
      "Sorted pitch_names, and length:\n",
      " ['0', '0.1.3', '0.1.3.5.8', '0.1.5', '0.1.5.8', '0.2.4.7', '0.2.7', '0.3.5.8', '0.3.7', '0.4', '0.4.7', '1.4.6.9', '1.5.8', '10', '10.1.3.6', '10.11.3.6', '10.2.5', '11.0', '11.0.2.4.7', '11.0.4.7', '11.1.3.5.7', '11.2', '11.2.4.6.7', '11.2.4.7', '11.4', '2.3.5.7.10', '2.3.7', '2.3.7.10', '2.4.7.10', '2.5.7.10', '2.5.7.9.10', '2.5.8.10', '2.5.9', '2.6', '2.6.9', '2.7', '3.4.8', '3.4.8.10', '3.4.8.11', '3.5.7.11', '3.6.9.11.0', '3.7.10', '3.8', '4.5.7.11', '4.5.7.9.0', '4.5.7.9.11', '4.5.9.0', '4.6.8.11.1', '4.6.8.9', '4.6.9', '4.6.9.0', '4.7', '4.7.9', '4.7.9.0', '4.7.9.11.0', '4.8', '4.9', '5', '5.6.10.1', '5.7.10', '5.7.10.1', '5.7.9.11.1', '5.8.10.0.1', '5.9', '5.9.0', '6.7.11.2', '6.7.9.11.2', '6.9.11.2', '7', '7.10.0.2.3', '7.10.0.3', '7.10.1', '7.10.2', '7.11.2', '7.8', '7.8.0', '7.8.0.3', '7.8.10.0.3', '7.9', '7.9.10.1.3', '7.9.11.1.3', '7.9.11.2', '7.9.11.2.4', '7.9.2', '8.0.3', '8.1', '8.10', '8.9.1.4', '8.9.11.1.4', '9.0.2.4.5', '9.0.2.5', '9.0.4', '9.1', '9.1.4', '9.10', '9.10.0.2.5', '9.10.2.5', '9.2', 'A1', 'A2', 'A3', 'A4', 'A5', 'B-1', 'B-2', 'B-3', 'B-4', 'B2', 'B3', 'B4', 'B5', 'C#2', 'C#4', 'C2', 'C3', 'C4', 'C5', 'D3', 'D4', 'D5', 'D6', 'E-2', 'E-3', 'E-4', 'E-5', 'E2', 'E3', 'E4', 'E5', 'F#2', 'F#4', 'F2', 'F3', 'F4', 'F5', 'F6', 'G#2', 'G#3', 'G#4', 'G1', 'G2', 'G3', 'G4'] , 143\n",
      "*************************************\n",
      "Notes to int dictonary \n",
      ": {'0': 0, '0.1.3': 1, '0.1.3.5.8': 2, '0.1.5': 3, '0.1.5.8': 4, '0.2.4.7': 5, '0.2.7': 6, '0.3.5.8': 7, '0.3.7': 8, '0.4': 9, '0.4.7': 10, '1.4.6.9': 11, '1.5.8': 12, '10': 13, '10.1.3.6': 14, '10.11.3.6': 15, '10.2.5': 16, '11.0': 17, '11.0.2.4.7': 18, '11.0.4.7': 19, '11.1.3.5.7': 20, '11.2': 21, '11.2.4.6.7': 22, '11.2.4.7': 23, '11.4': 24, '2.3.5.7.10': 25, '2.3.7': 26, '2.3.7.10': 27, '2.4.7.10': 28, '2.5.7.10': 29, '2.5.7.9.10': 30, '2.5.8.10': 31, '2.5.9': 32, '2.6': 33, '2.6.9': 34, '2.7': 35, '3.4.8': 36, '3.4.8.10': 37, '3.4.8.11': 38, '3.5.7.11': 39, '3.6.9.11.0': 40, '3.7.10': 41, '3.8': 42, '4.5.7.11': 43, '4.5.7.9.0': 44, '4.5.7.9.11': 45, '4.5.9.0': 46, '4.6.8.11.1': 47, '4.6.8.9': 48, '4.6.9': 49, '4.6.9.0': 50, '4.7': 51, '4.7.9': 52, '4.7.9.0': 53, '4.7.9.11.0': 54, '4.8': 55, '4.9': 56, '5': 57, '5.6.10.1': 58, '5.7.10': 59, '5.7.10.1': 60, '5.7.9.11.1': 61, '5.8.10.0.1': 62, '5.9': 63, '5.9.0': 64, '6.7.11.2': 65, '6.7.9.11.2': 66, '6.9.11.2': 67, '7': 68, '7.10.0.2.3': 69, '7.10.0.3': 70, '7.10.1': 71, '7.10.2': 72, '7.11.2': 73, '7.8': 74, '7.8.0': 75, '7.8.0.3': 76, '7.8.10.0.3': 77, '7.9': 78, '7.9.10.1.3': 79, '7.9.11.1.3': 80, '7.9.11.2': 81, '7.9.11.2.4': 82, '7.9.2': 83, '8.0.3': 84, '8.1': 85, '8.10': 86, '8.9.1.4': 87, '8.9.11.1.4': 88, '9.0.2.4.5': 89, '9.0.2.5': 90, '9.0.4': 91, '9.1': 92, '9.1.4': 93, '9.10': 94, '9.10.0.2.5': 95, '9.10.2.5': 96, '9.2': 97, 'A1': 98, 'A2': 99, 'A3': 100, 'A4': 101, 'A5': 102, 'B-1': 103, 'B-2': 104, 'B-3': 105, 'B-4': 106, 'B2': 107, 'B3': 108, 'B4': 109, 'B5': 110, 'C#2': 111, 'C#4': 112, 'C2': 113, 'C3': 114, 'C4': 115, 'C5': 116, 'D3': 117, 'D4': 118, 'D5': 119, 'D6': 120, 'E-2': 121, 'E-3': 122, 'E-4': 123, 'E-5': 124, 'E2': 125, 'E3': 126, 'E4': 127, 'E5': 128, 'F#2': 129, 'F#4': 130, 'F2': 131, 'F3': 132, 'F4': 133, 'F5': 134, 'F6': 135, 'G#2': 136, 'G#3': 137, 'G#4': 138, 'G1': 139, 'G2': 140, 'G3': 141, 'G4': 142}\n",
      "*************************************\n",
      "Net_in: [[44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136], [136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136], [136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136], [136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136], [136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136], [136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136], [136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136], [136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 90], [44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 90, 136], [136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 95, 136, 136, 25, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 89, 136, 136, 136, 96, 140, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 136, 136, 136, 136, 44, 136, 136, 136, 96, 114, 136, 136, 136, 136, 136, 136, 89, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 90, 136, 136]]\n",
      "Net_out: [136, 136, 136, 136, 136, 136, 90, 136, 136, 61]\n",
      "\n",
      "\n",
      "Output to Categorical:\n",
      " (3165, 143)\n"
     ]
    }
   ],
   "source": [
    "#count the number of possible outputs of notes\n",
    "n_vocab = (len(set(notes)))\n",
    "print(\"n_vocab:\",n_vocab)\n",
    "\n",
    "seq_length = 100\n",
    "\n",
    "#extract all pitch names\n",
    "pitch_names = sorted(set(item for item in notes))\n",
    "print(\"Sorted pitch_names, and length:\\n\",pitch_names,\",\",len(pitch_names))\n",
    "print(\"*************************************\")\n",
    "#We will create a dictonary to map each pitch to an integer\n",
    "note_to_int = dict((note,idx) for idx, note in enumerate(pitch_names))\n",
    "print(\"Notes to int dictonary \\n:\",note_to_int)\n",
    "print(\"*************************************\")\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "#We will create input and output sequences below\n",
    "for i in range(0, len(notes)-seq_length,1):\n",
    "    sequence_in = notes[i:i+seq_length]\n",
    "    sequence_out = notes[i+seq_length]\n",
    "    #Mapping pitches in sequence_in to corresponding mapping in 'notes_to_int':\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    #Mapping output note:\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "#print(\"Sq_in:\",sequence_in)\n",
    "#print(\"Sq_in_len:\",len(sequence_in))\n",
    "#print(\"Sq_out:\",sequence_out)\n",
    "#print(\"Sq_out_len:\",len(sequence_out))\n",
    "print(\"Net_in:\",network_input[:10])\n",
    "print(\"Net_out:\",network_output[:10])\n",
    "print(\"\\n\")\n",
    "n_pattern = len(network_input)\n",
    "#reshaping input to an LSTM compatible format\n",
    "network_input = numpy.reshape(network_input,(n_pattern, seq_length,1))\n",
    "#normalizing input\n",
    "network_input = network_input/float(n_vocab)\n",
    "network_output = tf.keras.utils.to_categorical(network_output) \n",
    "print(\"Output to Categorical:\\n\", network_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3165, 100, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(network_input.reshape([-1,100])[1])\n",
    "network_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 143)               36751     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 143)               0         \n",
      "=================================================================\n",
      "Total params: 5,419,151\n",
      "Trainable params: 5,419,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.8800 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 363s 115ms/step - loss: 1.8664\n",
      "Epoch 2/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6738 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 351s 111ms/step - loss: 1.6749\n",
      "Epoch 3/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6513 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 353s 111ms/step - loss: 1.6582\n",
      "Epoch 4/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6619 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 352s 111ms/step - loss: 1.6555\n",
      "Epoch 5/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6273 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 351s 111ms/step - loss: 1.6294\n",
      "Epoch 6/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6089 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 351s 111ms/step - loss: 1.6076\n",
      "Epoch 7/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.6027 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 351s 111ms/step - loss: 1.5924\n",
      "Epoch 8/10\n",
      "3136/3165 [============================>.] - ETA: 3s - loss: 1.5788 WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "3165/3165 [==============================] - 353s 111ms/step - loss: 1.5792\n",
      "Epoch 9/10\n",
      " 896/3165 [=======>......................] - ETA: 4:36:59 - loss: 1.5881"
     ]
    }
   ],
   "source": [
    "def music_learner(network_input, n_vocab):\n",
    "    '''Creating a neural net that'll take in the pitch matrix and\n",
    "       try to learn the patter in it\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(512, input_shape = (network_input.shape[1], \n",
    "                                             network_input.shape[2]), return_sequences=True))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(512,return_sequences=True))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.LSTM(512))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(n_vocab))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "model = music_learner(network_input, n_vocab)\n",
    "model.summary()\n",
    "\n",
    "'''We'll use model checkpoints to save weights after each epoch'''\n",
    "\n",
    "\n",
    "\n",
    "filepath = 'weights.{epoch:02d}-{loss:.5f}.h5'\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath,monitor='loss',save_best_only=True, mode='min')\n",
    "\n",
    "callback_list = [ckpt_callback]\n",
    "\n",
    "'''We can also use previously saved weights and continue our model from a checkpoint'''\n",
    "\n",
    "weights = \"\"\n",
    "if(len(weights)>0): model.load_weights(weights)\n",
    "\n",
    "'''Train the model'''\n",
    "model.fit(network_input, network_output, epochs = 10, batch_size=64,\n",
    "                                                      callbacks = callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1411d0531f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprediction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprediction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_input\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#We will generate network input again\n",
    "network_input = []\n",
    "output = []\n",
    "for i in range(0, len(notes) - seq_length, 1):\n",
    "    sequence_in = notes[i:i + seq_length]\n",
    "    sequence_out = notes[i + seq_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    output.append(note_to_int[sequence_out])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "    \n",
    "#Generate notes from the neural network based on a sequence of notes\n",
    "#Randomly sample a sequence from the input as a starting point for the prediction\n",
    "    \n",
    "start = numpy.random.randint(0, len(network_input)-1)\n",
    "int_to_note = dict((idx, note) for idx, note in enumerate(pitch_names))\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "\n",
    "# generate 500 notes\n",
    "for i,note_index in enumerate(range(500)):\n",
    "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    print('\\r', 'Predicted ', i, \" \",result, end='')\n",
    "    prediction_output.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a:\",\"\\n\",+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
